<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>神经网络 - 标签 - Fanstasy Player / 幻想系玩家</title>
    <link>https://fantasyplayer.link/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
    <description>个人博客， 技术博客， 思想分享，开发日志。</description>
    <generator>Hugo 0.150.0 &amp; FixIt v0.4.0-alpha.2-20250919092044-50488dfb</generator>
    <language>zh-CN</language>
    <managingEditor>aincvy@gmail.com (Aincvy)</managingEditor>
    <webMaster>aincvy@gmail.com (Aincvy)</webMaster>
    <lastBuildDate>Wed, 17 Jan 2024 16:03:28 +0800</lastBuildDate>
    <atom:link href="https://fantasyplayer.link/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>神经网络的一些简单了解</title>
      <link>https://fantasyplayer.link/program/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3/</link>
      <pubDate>Wed, 17 Jan 2024 16:03:28 +0800</pubDate><author>aincvy@gmail.com (Aincvy)</author>
      <guid>https://fantasyplayer.link/program/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3/</guid>
      <description>&lt;p&gt;本文中的神经网络指得是包含 输入层，隐层，输出层的那种结构。&lt;/p&gt;&#xA;&lt;p&gt;下面是笔者对神经网络的了解：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个层都是由N个神经元组成的。&lt;/li&gt;&#xA;&lt;li&gt;神经元由偏置和链接组成， 每个链接具有权重。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;基本上来说 输入层是第一层，在左边， 中间的是隐层， 输出层在最右边。 一个链接只会连接两个神经元。&lt;/li&gt;&#xA;&lt;li&gt;一种判断当前神经元是否激活的方式是： A = Sum(链接左侧神经元的激活值*链接权重) + 偏置， A &amp;gt; 0 ? 1 : 0&lt;/li&gt;&#xA;&lt;li&gt;上面这种方式， 当前神经元要么激活（&lt;em&gt;值为1&lt;/em&gt;）。 要么不激活（&lt;em&gt;值为0&lt;/em&gt;）.  这种方式产生的结果不够平滑&lt;/li&gt;&#xA;&lt;li&gt;另外一种获取当前神经网络激活值的方式是： B = Fun ( A )&lt;/li&gt;&#xA;&lt;li&gt;Fun 表示一个函数， 具体函数内容是什么，以及函数的输出结果是 [0, 1] 还是 [-1, 1]  笔者记不清了。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;调节神经网络的工作内容主要是调节链接的权重和神经元的偏置，  这俩都是一个具体的数值。&lt;/li&gt;&#xA;&lt;li&gt;每个神经元都会和下一层的全部神经元相连，  也会和上一层的全部神经元连接。&lt;/li&gt;&#xA;&lt;li&gt;隐层可以有多个。&lt;/li&gt;&#xA;&lt;li&gt;梯度下降算法是一种快速调整偏置和链接权重的算法。&lt;/li&gt;&#xA;&lt;li&gt;训练神经网络就是使用大量的样本数据和某个算法（比如梯度下降算法） 来调整链接权重和神经元偏置的过程。&lt;/li&gt;&#xA;&lt;li&gt;神经网络和直接使用编程语言编程是不同的解决问题的方式， 它们各有所长。&lt;/li&gt;&#xA;&lt;li&gt;神经网络可以用于图片识别。&lt;/li&gt;&#xA;&lt;li&gt;在进行图片识别的时候， 可以将2D图片转变成1维数组， 这个1维数组就是输入层。   图片的识别结果则作为输出层，比如 1 ~ 9 的数字。&lt;/li&gt;&#xA;&lt;li&gt;神经网络更像是是抽取样本数据的特点， 然后应用。 而非部件识别和组成。&#xA;&lt;ul&gt;&#xA;&lt;li&gt;抽取出现的特点不是简单的言语能表达的， 具有比较多的参数。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;神经网络和现在流行的transformer模型是不一样的。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 class=&#34;heading-element&#34; id=&#34;参考链接&#34;&gt;&lt;span&gt;参考链接&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e5%8f%82%e8%80%83%e9%93%be%e6%8e%a5&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=aircAruvnKk&amp;amp;ab_channel=3Blue1Brown&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://www.youtube.com/watch?v=aircAruvnKk&amp;ab_channel=3Blue1Brown&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
